#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
EEG Brain Wave Data Processor Service
è„‘æ³¢æ•°æ®å¤„ç†ä¸»æœåŠ¡

è´Ÿè´£ï¼š
1. è¿æ¥Emotiv EEGè®¾å¤‡è·å–è„‘æ³¢æ•°æ®
2. å®æ—¶åˆ†ææƒ…ç»ªçŠ¶æ€
3. é€šè¿‡HTTP APIå‘éŸ³é¢‘æœåŠ¡å‘é€æƒ…ç»ªæ•°æ®
"""

import math
import logging
import asyncio
import requests
import time
from cortex import Cortex
from typing import Dict, Any
import json

# ========================================================================================
# å…¨å±€é…ç½®ä¸æ—¥å¿— (Global Configuration & Logging)
# ========================================================================================

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- å‡­è¯é…ç½® ---
# Emotiv App Credentials
YOUR_APP_CLIENT_ID = '6OV53rWuPZiJo6419CHi4ppabSdqKpTgfYCU5mvV'
YOUR_APP_CLIENT_SECRET = 'XMWhqlpRTnQfe8a0b363jYFD976u7Ar17mQw2IWJT6eS2Z5LllaMckJbfbrSEqJYZ2LBpru6cvusWDapvjPSPutglsUwgNXYUzzcLKZqIhYOV52Rcy0YilZDJwoaQWnE'

# --- éŸ³é¢‘æœåŠ¡é…ç½® ---
AUDIO_SERVICE_URL = 'http://localhost:8080'
EMOTION_UPDATE_ENDPOINT = '/update_emotion'

# ========================================================================================
# æƒ…ç»ªè¯†åˆ«æ¨¡å— (Emotion Recognition Module)
# ========================================================================================

EMOTION_MAP = {
    "Happy": "Happy (å¼€å¿ƒ)",
    "Excited": "Excited (æ¿€åŠ¨)",
    "Surprised": "Surprised (æƒŠå–œ)",
    "Fear": "Fear (ææƒ§)",
    "Angry": "Angry (æ„¤æ€’)",
    "Contempt": "Contempt (è½»è”‘)",
    "Disgust": "Disgust (åŒæ¶)",
    "Miserable": "Miserable (ç—›è‹¦)",
    "Sad": "Sad (æ‚²ä¼¤)",
    "Depressed": "Depressed (æ²®ä¸§)",
    "Bored": "Bored (æ— èŠ)",
    "Tired": "Tired (ç–²å€¦)",
    "Sleepy": "Sleepy (å›°å€¦)",
    "Relaxed": "Relaxed (æ”¾æ¾)",
    "Pleased": "Pleased (å¹³é™)",
    "Neutral": "Neutral (ä¸­æ€§)" 
}

API_METRIC_ORDER = ['eng', 'exc', 'lex', 'str', 'rel', 'int']
METRIC_RANGES = {
    'eng': (0, 1), 'exc': (0, 1), 'lex': (0, 1), 'str': (0, 1),
    'rel': (0, 1), 'int': (0, 1)
}
WEIGHTS = {
    'arousal': {'exc': 0.4, 'str': 0.3, 'lex': 0.2, 'int': 0.15, 'eng': 0.1, 'rel': -0.4},
    'valence': {'rel': 0.35, 'int': 0.25, 'eng': 0.2, 'lex': 0.2, 'exc': 0.1, 'str': -0.5}
}

def normalize_to_neg_one_to_one(value, min_val, max_val):
    if max_val == min_val: 
        return 0
    return 2 * ((value - min_val) / (max_val - min_val)) - 1

def calculate_emotion_scores(metrics, weights):
    arousal = sum(weights['arousal'][key] * metrics[key] for key in API_METRIC_ORDER)
    valence = sum(weights['valence'][key] * metrics[key] for key in API_METRIC_ORDER)
    return max(-1, min(1, valence)), max(-1, min(1, arousal))

def get_precise_emotion(valence, arousal, neutral_threshold=0.1):
    intensity_raw = math.sqrt(valence**2 + arousal**2)
    
    # åŸå§‹å¼ºåº¦å½’ä¸€åŒ–åˆ°0-100èŒƒå›´
    intensity_normalized = min(100, (intensity_raw / math.sqrt(2)) * 100)
    
    # æ•°å­¦è¿ç®—ï¼šå½’ä¸€åŒ–åˆ°0-1 -> å¼€å¹³æ–¹ -> ä¹˜10 -> å›åˆ°0-100èŒƒå›´
    intensity_0_to_1 = intensity_normalized / 100.0
    intensity_sqrt = math.sqrt(intensity_0_to_1)
    intensity_amplified = intensity_sqrt * 10
    intensity_final = min(100, intensity_amplified * 10)
    
    if intensity_raw < neutral_threshold:
        return "Neutral (ä¸­æ€§)", intensity_final
        
    angle = math.degrees(math.atan2(arousal, valence))
    if angle < 0: 
        angle += 360
    
    emotion_label = "Neutral"

    if intensity_raw >= neutral_threshold:
        if 0 <= angle < 30: emotion_label = "Happy"
        elif 30 <= angle < 60: emotion_label = "Excited"
        elif 60 <= angle < 90: emotion_label = "Surprised"
        elif 90 <= angle < 112.5: emotion_label = "Fear"
        elif 112.5 <= angle < 135: emotion_label = "Angry"
        elif 135 <= angle < 157.5: emotion_label = "Contempt"
        elif 157.5 <= angle < 180: emotion_label = "Disgust"
        elif 180 <= angle < 198: emotion_label = "Miserable"
        elif 198 <= angle < 216: emotion_label = "Sad"
        elif 216 <= angle < 234: emotion_label = "Depressed"
        elif 234 <= angle < 252: emotion_label = "Bored"
        elif 252 <= angle < 270: emotion_label = "Tired"
        elif 270 <= angle < 300: emotion_label = "Sleepy"
        elif 300 <= angle < 330: emotion_label = "Relaxed"
        elif 330 <= angle < 360: emotion_label = "Pleased"
    
    return EMOTION_MAP.get(emotion_label, emotion_label), intensity_final

def analyze_emotion_from_sample(sample_list):
    raw_data = dict(zip(API_METRIC_ORDER, sample_list))
    normalized_metrics = {k: normalize_to_neg_one_to_one(v, *METRIC_RANGES[k]) for k, v in raw_data.items()}
    v, a = calculate_emotion_scores(normalized_metrics, WEIGHTS)
    emotion, intensity = get_precise_emotion(v, a)
    
    return emotion, intensity, v, a

# ========================================================================================
# éŸ³é¢‘æœåŠ¡é€šä¿¡æ¨¡å— (Audio Service Communication Module)
# ========================================================================================

class AudioServiceClient:
    def __init__(self, base_url: str):
        self.base_url = base_url
        self.session = requests.Session()
        self.last_emotion_time = 0
        
    def send_emotion_update(self, emotion: str, intensity: float, valence: float, arousal: float) -> bool:
        """å‘é€æƒ…ç»ªæ›´æ–°åˆ°éŸ³é¢‘æœåŠ¡"""
        current_time = time.time()
            
        try:
            data = {
                'emotion': emotion,
                'intensity': intensity,
                'valence': valence,
                'arousal': arousal,
                'timestamp': current_time
            }
            
            response = self.session.post(
                f"{self.base_url}{EMOTION_UPDATE_ENDPOINT}",
                json=data,
                timeout=2.0  # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°2ç§’
            )
            
            if response.status_code == 200:
                self.last_emotion_time = current_time
                return True
            else:
                logger.warning(f"éŸ³é¢‘æœåŠ¡è¿”å›é”™è¯¯çŠ¶æ€ç : {response.status_code}")
                return False
                
        except requests.exceptions.RequestException as e:
            logger.error(f"å‘é€æƒ…ç»ªæ•°æ®åˆ°éŸ³é¢‘æœåŠ¡å¤±è´¥: {e}")
            return False
    
    def check_audio_service_health(self) -> bool:
        """æ£€æŸ¥éŸ³é¢‘æœåŠ¡æ˜¯å¦å¯ç”¨"""
        try:
            response = self.session.get(f"{self.base_url}/health", timeout=2.0)
            return response.status_code == 200
        except requests.exceptions.RequestException:
            return False

# ========================================================================================
# EEGæ•°æ®å¤„ç†æ¨¡å— (EEG Data Processing Module)
# ========================================================================================

class EEGDataProcessor:
    def __init__(self, app_client_id, app_client_secret, audio_client: AudioServiceClient, **kwargs):
        logger.info("æ­£åœ¨åˆå§‹åŒ–Cortexå®¢æˆ·ç«¯...")
        self.cortex = Cortex(app_client_id, app_client_secret, debug_mode=False, **kwargs)
        self.cortex.bind(new_met_data=self.on_new_met_data)
        self.cortex.bind(inform_error=self.on_inform_error)
        self.cortex.bind(create_session_done=self.on_create_session_done)
        self.audio_client = audio_client
        self.is_connected = False
        
        # æ§åˆ¶è¾“å‡ºé¢‘ç‡çš„å˜é‡
        self.last_output_time = 0
        self.output_interval = 5.0  # 5ç§’è¾“å‡ºä¸€æ¬¡
        self.latest_emotion_data = None  # å­˜å‚¨æœ€æ–°çš„æƒ…ç»ªæ•°æ®
        
    def start(self, streams, headset_id=''):
        """å¯åŠ¨EEGæ•°æ®é‡‡é›†"""
        self.streams = streams
        if headset_id != '': 
            self.cortex.set_wanted_headset(headset_id)
        self.cortex.open()

    def subscribe_streams(self, streams):
        """è®¢é˜…æ•°æ®æµ"""
        logger.info("å‘é€æ•°æ®è®¢é˜…è¯·æ±‚...")
        self.cortex.sub_request(streams)

    def on_new_met_data(self, *args, **kwargs):
        """å¤„ç†æ–°çš„EEGæƒ…ç»ªæ•°æ®"""
        try:
            met_values = kwargs.get('data')['met']
            numerical_values = [met_values[i] for i in [1, 3, 5, 8, 10, 12]]
            emotion, intensity, v, a = analyze_emotion_from_sample(numerical_values)
            
            # æ›´æ–°æœ€æ–°çš„æƒ…ç»ªæ•°æ®
            self.latest_emotion_data = {
                'emotion': emotion,
                'intensity': intensity,
                'valence': v,
                'arousal': a,
                'timestamp': time.time()
            }
            
            # æ£€æŸ¥æ˜¯å¦åˆ°äº†è¾“å‡ºæ—¶é—´ï¼ˆæ¯5ç§’è¾“å‡ºä¸€æ¬¡ï¼‰
            current_time = time.time()
            if current_time - self.last_output_time >= self.output_interval:
                # æ§åˆ¶å°è¾“å‡º
                print(f"[{time.strftime('%H:%M:%S')}] å½“å‰æƒ…ç»ª: {emotion} | å¼ºåº¦: {intensity:.2f}/100 | (V: {v:.2f}, A: {a:.2f})")
                
                # å‘é€åˆ°éŸ³é¢‘æœåŠ¡
                success = self.audio_client.send_emotion_update(emotion, intensity/100.0, v, a)
                if success:
                    logger.info(f"å·²å‘é€æƒ…ç»ªæ•°æ®åˆ°éŸ³é¢‘æœåŠ¡: {emotion} ({intensity:.1f}%)")
                else:
                    logger.warning("å‘éŸ³é¢‘æœåŠ¡å‘é€æƒ…ç»ªæ•°æ®å¤±è´¥")
                
                # æ›´æ–°æœ€åè¾“å‡ºæ—¶é—´
                self.last_output_time = current_time
                
        except IndexError:
            logger.error(f"æ¥æ”¶åˆ°çš„ 'met' æ•°æ®æ ¼å¼ä¸å®Œæ•´: {kwargs.get('data')}")
        except Exception as e:
            logger.error(f"å¤„ç†EEGæ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")

    def get_latest_emotion_status(self):
        """è·å–æœ€æ–°çš„æƒ…ç»ªçŠ¶æ€ä¿¡æ¯"""
        if self.latest_emotion_data:
            data = self.latest_emotion_data
            time_since_last = time.time() - data['timestamp']
            return f"æœ€æ–°æƒ…ç»ª: {data['emotion']} | å¼ºåº¦: {data['intensity']:.1f}% | æ›´æ–°äº {time_since_last:.1f}ç§’å‰"
        else:
            return "æš‚æ— æƒ…ç»ªæ•°æ®"

    def on_create_session_done(self, *args, **kwargs):
        """Cortexä¼šè¯åˆ›å»ºå®Œæˆå›è°ƒ"""
        logger.info("Cortex ä¼šè¯åˆ›å»ºæˆåŠŸ, å‡†å¤‡è®¢é˜…æ•°æ®ã€‚")
        logger.info(f"æƒ…ç»ªæ•°æ®å°†æ¯ {self.output_interval} ç§’è¾“å‡ºä¸€æ¬¡")
        self.is_connected = True
        self.subscribe_streams(self.streams)

    def on_inform_error(self, *args, **kwargs):
        """Cortexé”™è¯¯å›è°ƒ"""
        logger.error(f"Cortex é”™è¯¯: {kwargs.get('error_data')}")
        self.is_connected = False

# ========================================================================================
# ä¸»ç¨‹åºå…¥å£ (Main Application Entry Point)
# ========================================================================================

def main():
    """ä¸»ç¨‹åºå…¥å£"""
    logger.info("å¯åŠ¨EEGè„‘æ³¢æ•°æ®å¤„ç†æœåŠ¡...")
    
    # æ£€æŸ¥å‡­è¯é…ç½®
    if YOUR_APP_CLIENT_ID == 'ä½ çš„Client ID' or YOUR_APP_CLIENT_SECRET == 'ä½ çš„Client Secret':
        logger.error("é”™è¯¯ï¼šè¯·åœ¨ä»£ç ä¸­å¡«å…¥ä½ çš„ Emotiv App Client ID å’Œ Client Secret!")
        return
    
    # åˆå§‹åŒ–éŸ³é¢‘æœåŠ¡å®¢æˆ·ç«¯
    audio_client = AudioServiceClient(AUDIO_SERVICE_URL)
    
    # æ£€æŸ¥éŸ³é¢‘æœåŠ¡æ˜¯å¦å¯ç”¨
    logger.info("æ£€æŸ¥éŸ³é¢‘æœåŠ¡è¿æ¥...")
    max_retries = 30  # æœ€å¤šç­‰å¾…30ç§’
    retry_count = 0
    
    while retry_count < max_retries:
        if audio_client.check_audio_service_health():
            logger.info("éŸ³é¢‘æœåŠ¡è¿æ¥æˆåŠŸ!")
            break
        else:
            logger.info(f"ç­‰å¾…éŸ³é¢‘æœåŠ¡å¯åŠ¨... ({retry_count + 1}/{max_retries})")
            time.sleep(1)
            retry_count += 1
    
    if retry_count >= max_retries:
        logger.error("æ— æ³•è¿æ¥åˆ°éŸ³é¢‘æœåŠ¡ï¼Œè¯·ç¡®ä¿éŸ³é¢‘æœåŠ¡å·²å¯åŠ¨!")
        return
    
    # åˆå§‹åŒ–EEGæ•°æ®å¤„ç†å™¨
    eeg_processor = EEGDataProcessor(
        YOUR_APP_CLIENT_ID, 
        YOUR_APP_CLIENT_SECRET,
        audio_client
    )
    
    # å¯åŠ¨EEGæ•°æ®é‡‡é›†
    logger.info("å¯åŠ¨EEGæ•°æ®é‡‡é›†...")
    logger.info("è¯·æˆ´ä¸Šä½ çš„Emotivè®¾å¤‡å¹¶ç¡®ä¿CortexæœåŠ¡æ­£åœ¨è¿è¡Œã€‚")
    logger.info("ğŸ’¡ ç³»ç»Ÿå°†æ¯5ç§’è¾“å‡ºä¸€æ¬¡æƒ…ç»ªçŠ¶æ€ï¼Œè€Œä¸æ˜¯æ¯æ¡æ•°æ®éƒ½è¾“å‡º")
    
    try:
        eeg_processor.start(['met'])
        
        # ä¿æŒç¨‹åºè¿è¡Œ
        logger.info("EEGè„‘æ³¢æ•°æ®å¤„ç†æœåŠ¡æ­£åœ¨è¿è¡Œ...")
        logger.info("ğŸ“Š å®æ—¶æ•°æ®é‡‡é›†ä¸­ï¼Œæ¯5ç§’æ±‡æ€»è¾“å‡ºä¸€æ¬¡æƒ…ç»ªçŠ¶æ€")
        logger.info("æŒ‰Ctrl+Cåœæ­¢æœåŠ¡")
        
        while True:
            time.sleep(1)
            if not eeg_processor.is_connected:
                logger.warning("EEGè®¾å¤‡è¿æ¥ä¸¢å¤±ï¼Œå°è¯•é‡æ–°è¿æ¥...")
                
    except KeyboardInterrupt:
        logger.info("æ¥æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨å…³é—­æœåŠ¡...")
    except Exception as e:
        logger.error(f"ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
    finally:
        logger.info("EEGè„‘æ³¢æ•°æ®å¤„ç†æœåŠ¡å·²é€€å‡ºã€‚")

if __name__ == "__main__":
    main() 