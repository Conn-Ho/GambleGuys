from camel.models import AzureOpenAIModel
from camel.types import ModelType
from camel.agents import ChatAgent
from camel.messages import BaseMessage
import os
import sys
import re
from flask import Flask, request, jsonify
from flask_cors import CORS

sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from camel_agent.toolkits.imgen_tool import ImageGenerationToolkit
from camel_agent.toolkits import MemoryToolkit
from camel_agent.memory.memory import memory
from camel_agent.prompts.leading_prompt import leading_prompt  # ä½¿ç”¨æ•…äº‹å¼•å¯¼æç¤ºè¯
from camel_agent.libs.imgen import generate_image

os.environ["AZURE_OPENAI_API_KEY"] = "ES3vLOAy8MUTMui8udIAk2vZO1Fo7qCBHKlaAvcprOXicYTkjzwbJQQJ99BDACHYHv6XJ3w3AAAAACOG4FT8"
os.environ["AZURE_OPENAI_ENDPOINT"] = "https://ai-philxia4932ai122623990161.openai.azure.com/"
os.environ["AZURE_API_VERSION"] = "2024-02-15-preview"
os.environ["AZURE_DEPLOYMENT_NAME"] = "gpt-4.1"  # ä¿®æ”¹ä¸ºæ­£ç¡®çš„éƒ¨ç½²åç§°

DOUBAO_API_KEY = "9184e6fa-3267-4188-bf11-094bc7536823"
os.environ["ARK_API_KEY"] = DOUBAO_API_KEY

app = Flask(__name__)
CORS(app)

def init_model():
    try:
        return AzureOpenAIModel(
            model_type=ModelType.GPT_4O_MINI,
            model_config_dict={
                "temperature": 0.8,
                "max_tokens": 1200,
                "top_p": 0.95,
                "stream": False
            }
        )
    except Exception as e:
        print(f"Error initializing Azure OpenAI model: {str(e)}")
        return None

def init_tools():
    imgen_toolkit = ImageGenerationToolkit()
    memory_toolkit = MemoryToolkit(memory)
    all_tools = []
    all_tools.extend(imgen_toolkit.get_tools())
    all_tools.extend(memory_toolkit.get_tools())
    return all_tools, imgen_toolkit

def create_agent(model, tools, memory):
    """åˆ›å»ºAIæ•…äº‹å¼•å¯¼åŠ©æ‰‹ä»£ç†"""
    sys_msg = BaseMessage.make_assistant_message(
        role_name='AI Story Guide',
        content=str(leading_prompt)  # ä½¿ç”¨leading_promptä¸­çš„æ•…äº‹å¼•å¯¼é€»è¾‘
    )
    return ChatAgent(
        system_message=sys_msg,
        model=model,
        tools=tools,
        memory=memory
    )

def get_memory_context(memory):
    if hasattr(memory, 'chat_messages') and memory.chat_messages:
        chat_history = memory.chat_messages[-10:]
        if chat_history:
            context = "\nå†å²å¯¹è¯è®°å¿†\n"
            for i, msg in enumerate(chat_history):
                role = msg.role_name if hasattr(msg, 'role_name') else msg.role
                content = msg.content[:200] + "..." if len(msg.content) > 200 else msg.content
                context += f"{i+1}. {role}: {content}\n"
            return context + "è¯·åŸºäºä»¥ä¸Šå†å²ç»§ç»­æ•…äº‹\n"
    return "\næ–°çš„å¯¹è¯å¼€å§‹\n"

def generate_image_prompt(story_content, model=None):
    """ä½¿ç”¨AzureOpenAIæ ¹æ®æ•…äº‹å†…å®¹ç”Ÿæˆå›¾ç‰‡æç¤ºè¯"""
    if not model:
        # å¦‚æœæ²¡æœ‰ä¼ å…¥æ¨¡å‹ï¼Œä½¿ç”¨å…¨å±€æ¨¡å‹
        if 'model' in globals() and globals()['model'] is not None:
            used_model = globals()['model']
        else:
            used_model = init_model()
    else:
        used_model = model
    
    if not used_model:
        # å¦‚æœæ¨¡å‹ä¸å¯ç”¨ï¼Œè¿”å›åŸºç¡€æç¤ºè¯
        print("âš ï¸ AzureOpenAIæ¨¡å‹ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€æç¤ºè¯")
        return f"pixel art dreamcore scene, {story_content[:50]}, nostalgic atmosphere, dreamy blue-purple tones, low saturation, 8-bit style"
    
    try:
        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å›¾åƒæç¤ºè¯ç”Ÿæˆä¸“å®¶ã€‚è¯·æ ¹æ®ç»™å®šçš„æ•…äº‹å†…å®¹ï¼Œç”Ÿæˆä¸€ä¸ªé€‚åˆçš„è‹±æ–‡å›¾åƒæç¤ºè¯ã€‚

è¦æ±‚ï¼š
1. é£æ ¼ï¼šåƒç´ é£+æ¢¦æ ¸é£æ ¼ (pixel art + dreamcore)
2. è‰²è°ƒï¼šè“ç´«è°ƒï¼Œä½é¥±å’Œåº¦
3. æ°›å›´ï¼šæ€€æ—§ã€æ¢¦å¹»ã€æ¸©é¦¨
4. é•¿åº¦ï¼šä¸è¶…è¿‡80ä¸ªè‹±æ–‡å•è¯
5. åŒ…å«å…·ä½“çš„åœºæ™¯ã€ç‰©ä½“ã€æ°›å›´æè¿°
6. ä¸è¦åŒ…å«äººç‰©é¢éƒ¨ç‰¹å¾

ç¤ºä¾‹æ ¼å¼ï¼špixel art dreamcore scene, [å…·ä½“åœºæ™¯æè¿°], nostalgic atmosphere, soft blue-purple tones, low saturation, 8-bit style

è¯·åªè¿”å›æç¤ºè¯ï¼Œä¸è¦æ·»åŠ å…¶ä»–è§£é‡Šã€‚"""

        user_prompt = f"è¯·ä¸ºä»¥ä¸‹æ•…äº‹å†…å®¹ç”Ÿæˆå›¾åƒæç¤ºè¯ï¼š\n\n{story_content}"
        
        # åˆ›å»ºä¸´æ—¶çš„ChatAgentæ¥ç”Ÿæˆæç¤ºè¯
        sys_msg = BaseMessage.make_assistant_message(
            role_name='Image Prompt Generator',
            content=system_prompt
        )
        
        temp_agent = ChatAgent(
            system_message=sys_msg,
            model=used_model
        )
        
        user_message = BaseMessage.make_user_message(
            role_name='User',
            content=user_prompt
        )
        
        # è°ƒç”¨ä¸´æ—¶agentç”Ÿæˆæç¤ºè¯
        response = temp_agent.step(user_message)
        
        if response and response.msgs and len(response.msgs) > 0:
            generated_prompt = response.msgs[0].content.strip()
            print(f"ğŸ¨ AIç”Ÿæˆçš„æç¤ºè¯: {generated_prompt}")
            return generated_prompt
        else:
            print("âš ï¸ AzureOpenAIè¿”å›ç©ºå“åº”ï¼Œä½¿ç”¨åŸºç¡€æç¤ºè¯")
            return f"pixel art dreamcore scene, {story_content[:50]}, nostalgic atmosphere, dreamy blue-purple tones, low saturation, 8-bit style"
            
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå›¾ç‰‡æç¤ºè¯æ—¶å‡ºé”™: {str(e)}")
        # å‡ºé”™æ—¶è¿”å›åŸºç¡€æç¤ºè¯
        base_prompt = "pixel art dreamcore scene"
        words = story_content.lower().split()
        keywords = [word for word in words if len(word) > 3 and word.isalpha()][:3]
        if keywords:
            return f"{base_prompt}, {', '.join(keywords)}, nostalgic atmosphere, dreamy blue-purple tones, low saturation, 8-bit style"
        return f"{base_prompt}, nostalgic atmosphere, dreamy blue-purple tones, low saturation, 8-bit style"

def extract_story_content(ai_response):
    story_pattern = re.search(r"---\s*(.*?)\s*---", ai_response, re.DOTALL)
    if story_pattern:
        return story_pattern.group(1).strip()
    
    story_match = re.search(r"Storyï¼ˆæ•…äº‹ï¼‰[:ï¼š]\s*(.*?)(?=\n\s*Imageï¼ˆ|ä¸€å¹…|ä¸€æ®µ|$)", ai_response, re.DOTALL)
    if story_match:
        return story_match.group(1).strip()
    
    cleaned = ai_response
    patterns_to_remove = [
        r'ç”¨æˆ·.*?[:ï¼š].*?\n',
        r'åƒç´ é£.*?éŸ³ä¹.*?\n',
        r'8-bit.*?\n',
        r'æ¢¦æ ¸.*?\n',
        r'è°ƒç”¨ï¼š.*?\n',
        r'å‚æ•°ï¼š.*?\n',
        r'æè¿°[:ï¼š].*?\n',
        r'\[.*?\]\(.*?\)',
        r'!\[.*?\]\(.*?\)',
        r'\{.*?\}',
    ]
    for pattern in patterns_to_remove:
        cleaned = re.sub(pattern, '', cleaned)
    
    cleaned = re.sub(r'\n\s*\n\s*\n+', '\n\n', cleaned)
    return cleaned.strip()

model = init_model()
tools, imgen_toolkit = init_tools()
agent = create_agent(model, tools, memory)

user_preferences = {
    "æ•…äº‹ç±»å‹": "æ¸©æš–ã€æ²»æ„ˆçš„æ•…äº‹",
    "å›¾ç‰‡é£æ ¼": "åƒç´ é£+æ¢¦æ ¸é£çš„é£æ™¯ç”»",
    "ä¸»è§’åå¥½": "å–œæ¬¢å›å¿†å¾€äº‹",
    "éŸ³ä¹é£æ ¼è¦æ±‚": "æ¢¦æ ¸+åƒç´ é£æ ¼"
}

# æ•…äº‹åœºæ™¯è®¡æ•°å™¨ï¼ˆåœ¨å®é™…åº”ç”¨ä¸­åº”è¯¥ä¿å­˜åˆ°æ•°æ®åº“ï¼‰
scene_counter = 0
story_state = {
    "scenes_count": 0,
    "story_active": True,
    "last_scene_type": None
}

@app.route('/api/chat', methods=['POST'])
def chat():
    if model is None:
        return jsonify({
            'error': 'Azure OpenAI model initialization failed. Please check your configuration.',
            'status': 'error'
        }), 500
        
    global story_state
    
    data = request.json
    user_input = data.get('message', '')
    
    if not user_input:
        return jsonify({'error': 'æ¶ˆæ¯ä¸èƒ½ä¸ºç©º'}), 400
        
    try:
        # æ›´æ–°åœºæ™¯è®¡æ•°
        story_state["scenes_count"] += 1
        
        # è·å–è®°å¿†ä¸Šä¸‹æ–‡
        memory_context = get_memory_context(memory)
        
        # æ„å»ºæ•…äº‹å¼•å¯¼ä¸Šä¸‹æ–‡
        story_guidance = f"""
å½“å‰åœºæ™¯æ•°: {story_state["scenes_count"]}
æ•…äº‹çŠ¶æ€: {"è¿›è¡Œä¸­" if story_state["story_active"] else "å·²ç»“æŸ"}

è¯·éµå¾ªä»¥ä¸‹æ•…äº‹å¼•å¯¼åŸåˆ™ï¼š
1. å›å¤å­—æ•°é™åˆ¶åœ¨150å­—ä»¥å†…
2. æè¿°ç®€æ´æ˜äº†ï¼Œé¿å…è¿‡å¤šç»†èŠ‚
3. æ¯æ¬¡æ¨è¿›ä¸€ä¸ªå°æƒ…èŠ‚
4. æ¯ä¸ªåœºæ™¯æŒç»­çº¦5åˆ†é’Ÿä½“éªŒæ—¶é—´
5. æ¯10ä¸ªåœºæ™¯åæœ‰20%æ¦‚ç‡è§¦å‘BEç»“å±€
6. ç©å®¶è¡Œä¸ºéœ€ç¬¦åˆå½“å‰ä¸–ç•Œè§‚çš„äººç±»èƒ½åŠ›èŒƒå›´
7. æ ¹æ®å‰§æƒ…è°ƒæ•´å¯¹è¯è¯­æ°”å’Œç©å®¶æƒ…ç»ª
8. åŒ…å«10%çš„éšæœºäº‹ä»¶å¢åŠ ä¸å¯é¢„æµ‹æ€§

ç”¨æˆ·åå¥½: {', '.join([f'{k}:{v}' for k, v in user_preferences.items()])}
"""
        
        enhanced_content = f"""
{memory_context}

{story_guidance}

ç”¨æˆ·è¾“å…¥: {user_input}

è¯·åŸºäºä¸Šè¿°å¼•å¯¼åŸåˆ™å’Œå†å²è®°å¿†ï¼Œç»§ç»­æ¨è¿›æ•…äº‹å‘å±•ã€‚è®°ä½è¦ä¿æŒæ•…äº‹çš„è¿è´¯æ€§å’Œæƒ…æ„Ÿä¸€è‡´æ€§ã€‚
"""
        
        user_message = BaseMessage.make_user_message(
            role_name='User',
            content=enhanced_content
        )
        
        # æ‰§è¡Œå¯¹è¯
        response = agent.step(user_message)
        full_reply = response.msgs[0].content if response.msgs else "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›å¤ã€‚"
        
        # æå–æ•…äº‹å†…å®¹
        story_content = extract_story_content(full_reply)
        
        # åˆå§‹åŒ–å›¾ç‰‡URLå˜é‡
        image_url = None
        
        # æ¯æ¬¡å¯¹è¯éƒ½ç”Ÿæˆå›¾ç‰‡
        should_generate_image = True  # ç®€åŒ–ï¼šæ¯æ¬¡éƒ½ç”Ÿæˆå›¾ç‰‡
        
        if should_generate_image and story_content:
            prompt = generate_image_prompt(story_content, model)  # ä¼ å…¥æ¨¡å‹å‚æ•°
            print(f"ğŸ¨ å‡†å¤‡ç”Ÿæˆå›¾ç‰‡ï¼Œæç¤ºè¯: {prompt}")
            result = generate_image(prompt=prompt, api_key=DOUBAO_API_KEY)
            print(f"ğŸ¨ å›¾ç‰‡ç”Ÿæˆç»“æœ: {result}")
            if result.get("success"):
                image_url = result["image_url"]
                print(f"âœ… å›¾ç‰‡ç”ŸæˆæˆåŠŸ: {image_url}")
            else:
                print(f"âŒ å›¾ç‰‡ç”Ÿæˆå¤±è´¥: {result.get('error', 'Unknown error')}")
        
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç»“å±€æ¡ä»¶
        if story_state["scenes_count"] >= 10 and story_state["scenes_count"] % 10 == 0:
            # 20%æ¦‚ç‡è§¦å‘BEç»“å±€ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            import random
            if random.random() < 0.2:
                story_state["story_active"] = False
                story_content += "\n\n[æ•…äº‹åœ¨æ­¤åˆ»æˆ›ç„¶è€Œæ­¢...]"
        
        return jsonify({
            'reply': story_content,
            'image_url': image_url,
            'status': 'success',
            'scene_count': story_state["scenes_count"],
            'story_active': story_state["story_active"]
        })
    except Exception as e:
        print(f"Error in chat endpoint: {str(e)}")
        return jsonify({
            'error': 'å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•',
            'status': 'error'
        }), 500

@app.route('/api/test-image', methods=['POST'])
def test_image():
    data = request.json
    prompt = data.get('prompt', 'pixel art dreamcore scene, peaceful landscape')
    result = generate_image(prompt=prompt, api_key=DOUBAO_API_KEY)
    return jsonify({'result': result, 'status': 'success'})

@app.route('/api/debug-image', methods=['POST'])
def debug_image():
    """è°ƒè¯•å›¾ç‰‡ç”ŸæˆåŠŸèƒ½"""
    data = request.json
    prompt = data.get('prompt', 'pixel art dreamcore scene')
    
    print(f"è°ƒè¯• - ä½¿ç”¨API Key: {DOUBAO_API_KEY[:10]}...")
    print(f"è°ƒè¯• - ç”Ÿæˆæç¤ºè¯: {prompt}")
    
    result = generate_image(prompt=prompt, api_key=DOUBAO_API_KEY)
    
    print(f"è°ƒè¯• - ç”Ÿæˆç»“æœ: {result}")
    
    return jsonify({
        'prompt': prompt,
        'api_key_preview': DOUBAO_API_KEY[:10] + "...",
        'result': result,
        'status': 'debug'
    })

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
